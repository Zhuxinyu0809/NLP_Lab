{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T05:18:05.592673Z",
     "iopub.status.busy": "2025-10-14T05:18:05.592515Z",
     "iopub.status.idle": "2025-10-14T05:19:37.346148Z",
     "shell.execute_reply": "2025-10-14T05:19:37.345420Z",
     "shell.execute_reply.started": "2025-10-14T05:18:05.592658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T05:20:49.521921Z",
     "iopub.status.busy": "2025-10-14T05:20:49.521603Z",
     "iopub.status.idle": "2025-10-14T05:27:38.466259Z",
     "shell.execute_reply": "2025-10-14T05:27:38.465609Z",
     "shell.execute_reply.started": "2025-10-14T05:20:49.521897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:21:00.793670: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760419260.986714      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760419261.042540      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1600\n",
      "Test set size: 5001\n",
      "Positive/Negative sample distribution:\n",
      "sentiment\n",
      "1    801\n",
      "0    799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training data: 1440, Validation data: 160\n",
      "Training data distribution: {1: 721, 0: 719}\n",
      "Validation data distribution: {0: 80, 1: 80}\n",
      "\n",
      "Loading model: microsoft/deberta-v3-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5243708ac74c538beaa9631e1530ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690c89fd3d22457cb972ec05f6264586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a821f4cc6404c57b65862388adad285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3afd3e784bf4496a5ba9ce15466afd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821d6cc19a48423ba3e079e5a020fa3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139e912ab10642f6baec563c9d5be8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c03c8e866b4f589c1567199c6d5e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6094e372ceb42d9ba7da1b7a684c2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 02:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on validation set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0000\n",
      "Validation F1 Score: 1.0000\n",
      "\n",
      "Retraining with full training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27edc8c58a354153a66f18d39c24881e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 02:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Submission file saved: deberta_submission.csv\n",
      "Prediction distribution: {0: 2522, 1: 2479}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DeBERTa-v3 Movie Review Sentiment Classification - Full Code for Kaggle Competition\n",
    "Suitable for: https://www.kaggle.com/competitions/py-sphere-movie-review-sentiment-challenge\n",
    "Current baseline: 0.81368 → Target: 0.90+\n",
    "\"\"\"\n",
    "\n",
    "# ===== 1. Install Dependencies =====\n",
    "# Run in the first cell of Kaggle Notebook:\n",
    "# !pip install transformers datasets accelerate -U -q\n",
    "\n",
    "# ===== 2. Import Libraries =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, # Used to load the tokenizer for the pre-trained model\n",
    "    AutoModelForSequenceClassification, # Used to load the pre-trained model for sequence classification\n",
    "    TrainingArguments, # Defines the training configuration for the Trainer\n",
    "    Trainer # A class for training PyTorch models with 🤗 Transformers\n",
    ")\n",
    "from datasets import Dataset # Hugging Face's Dataset object for efficient data handling\n",
    "from sklearn.model_selection import train_test_split # Utility for splitting datasets into train and test sets\n",
    "from sklearn.metrics import accuracy_score, f1_score # Metrics to evaluate model performance\n",
    "import warnings # Used to manage warnings\n",
    "warnings.filterwarnings('ignore') # Ignores all warning messages for cleaner output\n",
    "\n",
    "# ===== 3. Set Random Seed (for reproducibility) =====\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Sets the random seed for NumPy, PyTorch, and CUDA to ensure reproducibility\n",
    "    of experiments.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed) # Seed for NumPy random number generator\n",
    "    torch.manual_seed(seed) # Seed for PyTorch on CPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed) # Seed for PyTorch on all CUDA GPUs\n",
    "\n",
    "set_seed(42) # Call the function to set the global random seed\n",
    "\n",
    "# ===== 4. Load Data =====\n",
    "# Modify to your Kaggle data path if different\n",
    "# Loads the training, testing, and sample submission data from CSV files.\n",
    "train_df = pd.read_csv('/kaggle/input/py-sphere-movie-review-sentiment-challenge/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/py-sphere-movie-review-sentiment-challenge/test.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/py-sphere-movie-review-sentiment-challenge/sample_submission.csv')\n",
    "\n",
    "# Prints the size of the datasets and the distribution of sentiment labels in the training set.\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(f\"Positive/Negative sample distribution:\\n{train_df['sentiment'].value_counts()}\")\n",
    "\n",
    "# ===== 5. Data Preprocessing =====\n",
    "# Clean text data\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Simple text cleaning function: converts text to string and removes leading/trailing whitespace.\n",
    "    Further cleaning (e.g., removing punctuation, special characters) might be added here.\n",
    "    \"\"\"\n",
    "    text = str(text).strip() # Ensure text is a string and remove whitespace\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'review' columns of both training and testing DataFrames.\n",
    "train_df['review'] = train_df['review'].apply(clean_text)\n",
    "test_df['review'] = test_df['review'].apply(clean_text)\n",
    "\n",
    "# Split training set into training and validation sets (Crucial for realistic performance evaluation)\n",
    "# Splits `train_df` into `train_data` (90%) and `val_data` (10%).\n",
    "# `test_size=0.1`: 10% of the original training data will be used for validation.\n",
    "# `random_state=42`: Ensures the split is reproducible.\n",
    "# `stratify=train_df['sentiment']`: Maintains the same proportion of sentiment classes\n",
    "#                                   in both the training and validation splits as in the original `train_df`.\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=train_df['sentiment'] # Keep category distribution consistent\n",
    ")\n",
    "\n",
    "# Prints the sizes and sentiment distributions of the newly created training and validation sets.\n",
    "print(f\"\\nTraining data: {len(train_data)}, Validation data: {len(val_data)}\")\n",
    "print(f\"Training data distribution: {train_data['sentiment'].value_counts().to_dict()}\")\n",
    "print(f\"Validation data distribution: {val_data['sentiment'].value_counts().to_dict()}\")\n",
    "\n",
    "# ===== 6. Load Model and Tokenizer =====\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\" # Specifies the name of the pre-trained DeBERTa-v3 base model\n",
    "# If GPU memory is insufficient, you can use the small version:\n",
    "# MODEL_NAME = \"microsoft/deberta-v3-small\"\n",
    "\n",
    "print(f\"\\nLoading model: {MODEL_NAME}\")\n",
    "# Loads the tokenizer associated with the specified pre-trained model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# Loads the pre-trained DeBERTa-v3 model for sequence classification.\n",
    "# `num_labels=2`: Configures the model for binary classification (positive/negative sentiment).\n",
    "# `ignore_mismatched_sizes=True`: Allows loading weights even if some layers' sizes don't perfectly match,\n",
    "#                                  useful if the pre-trained model had a different number of output labels.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# ===== 7. Data Encoding =====\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenizes a batch of text examples using the pre-trained tokenizer.\n",
    "    `padding='max_length'`: Pads shorter sequences to `max_length`.\n",
    "    `truncation=True`: Truncates longer sequences to `max_length`.\n",
    "    `max_length=256`: Sets the maximum sequence length for tokenization.\n",
    "                      Can be adjusted; longer sequences might yield better results but are slower.\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        examples['review'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256 # Adjustable, longer might be slower but better results\n",
    "    )\n",
    "\n",
    "# Convert Pandas DataFrames to Hugging Face Dataset format\n",
    "# `from_pandas` creates a Dataset object from a DataFrame, selecting specified columns.\n",
    "train_dataset = Dataset.from_pandas(train_data[['review', 'sentiment']])\n",
    "val_dataset = Dataset.from_pandas(val_data[['review', 'sentiment']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['review']])\n",
    "\n",
    "# Rename column (Trainer requires 'label' column)\n",
    "# The `Trainer` expects the target column to be named 'labels', so we rename 'sentiment'.\n",
    "train_dataset = train_dataset.rename_column('sentiment', 'labels')\n",
    "val_dataset = val_dataset.rename_column('sentiment', 'labels')\n",
    "\n",
    "# Batch encoding\n",
    "print(\"\\nEncoding data...\")\n",
    "# Apply the `tokenize_function` to each dataset in batches.\n",
    "# `batched=True`: Processes multiple examples at once for efficiency.\n",
    "# `remove_columns=['review']`: Removes the original 'review' text column after tokenization\n",
    "#                               to save memory, as the tokenized IDs are now the features.\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=['review'])\n",
    "val_tokenized = val_dataset.map(tokenize_function, batched=True, remove_columns=['review'])\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True, remove_columns=['review'])\n",
    "\n",
    "# ===== 8. Define Evaluation Metrics =====\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Computes accuracy and F1-score for evaluation.\n",
    "    `eval_pred` is a tuple containing predictions (logits) and true labels.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred # Unpack predictions (raw model outputs) and true labels\n",
    "    predictions = np.argmax(logits, axis=-1) # Convert logits to class predictions (0 or 1)\n",
    "    acc = accuracy_score(labels, predictions) # Calculate accuracy\n",
    "    f1 = f1_score(labels, predictions, average='binary') # Calculate F1-score for binary classification\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# ===== 9. Training Arguments Setup =====\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', # Directory where model checkpoints and outputs will be saved\n",
    "\n",
    "    # ⭐ Fixed parameter names for consistency with Hugging Face Transformers updates\n",
    "    eval_strategy='epoch', # Evaluate every epoch\n",
    "    save_strategy='epoch', # Save model checkpoints every epoch\n",
    "\n",
    "    # Learning rate and batch size\n",
    "    learning_rate=2e-5, # Initial learning rate for the optimizer\n",
    "    per_device_train_batch_size=16, # Batch size per GPU/CPU for training (reduce if Out Of Memory)\n",
    "    per_device_eval_batch_size=32, # Batch size per GPU/CPU for evaluation\n",
    "\n",
    "    # Number of training epochs\n",
    "    num_train_epochs=3, # Total number of training epochs (can try 4-5 for potentially better results)\n",
    "\n",
    "    # Regularization\n",
    "    weight_decay=0.01, # L2 regularization applied to all layers except bias and layer normalization weights\n",
    "\n",
    "    # Early stopping and model saving\n",
    "    load_best_model_at_end=True, # Loads the best model (based on `metric_for_best_model`) at the end of training\n",
    "    metric_for_best_model='accuracy', # Metric used to determine the \"best\" model to load\n",
    "\n",
    "    # Logging\n",
    "    logging_dir='./logs', # Directory for storing logs\n",
    "    logging_steps=50, # Log training progress every 50 steps\n",
    "\n",
    "    # Other settings\n",
    "    report_to='none', # Disables reporting to experiment tracking platforms like Weights & Biases\n",
    "    seed=42, # Random seed for reproducibility during training\n",
    "    fp16=torch.cuda.is_available(), # Automatically enables mixed precision training if a CUDA GPU is available\n",
    ")\n",
    "\n",
    "# ===== 10. Create Trainer and Train =====\n",
    "# Initializes the Hugging Face Trainer with the model, arguments, datasets, tokenizer, and metrics.\n",
    "trainer = Trainer(\n",
    "    model=model, # The 🤗 Transformers model to train\n",
    "    args=training_args, # The training arguments\n",
    "    train_dataset=train_tokenized, # The tokenized training dataset\n",
    "    eval_dataset=val_tokenized, # The tokenized validation dataset\n",
    "    tokenizer=tokenizer, # The tokenizer used for encoding (optional, but good practice to pass)\n",
    "    compute_metrics=compute_metrics, # The function to compute metrics during evaluation\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "trainer.train() # Starts the training process\n",
    "\n",
    "# ===== 11. Validation Set Evaluation =====\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "# Evaluates the trained model on the validation set.\n",
    "eval_results = trainer.evaluate()\n",
    "# Prints the accuracy and F1-score on the validation set.\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "# ===== 12. Retrain on Full Training Data (Optional, usually improves by 1-2%) =====\n",
    "print(\"\\nRetraining with full training data...\")\n",
    "# Creates a full training dataset from the original `train_df`.\n",
    "full_train_dataset = Dataset.from_pandas(train_df[['review', 'sentiment']])\n",
    "full_train_dataset = full_train_dataset.rename_column('sentiment', 'labels') # Rename 'sentiment' to 'labels'\n",
    "full_train_tokenized = full_train_dataset.map(tokenize_function, batched=True, remove_columns=['review']) # Tokenize\n",
    "\n",
    "# Re-create Trainer (without validation set for final training)\n",
    "# A new Trainer is created for training on the *entire* original training dataset.\n",
    "# Validation is usually skipped in this final stage as the goal is to maximize performance on test data.\n",
    "final_trainer = Trainer(\n",
    "    model=model, # The same model (potentially fine-tuned from previous training)\n",
    "    args=TrainingArguments(\n",
    "        output_dir='./final_results', # Output directory for this final training run\n",
    "        per_device_train_batch_size=16, # Training batch size\n",
    "        num_train_epochs=3, # Number of epochs for this final training\n",
    "        learning_rate=2e-5, # Learning rate\n",
    "        weight_decay=0.01, # Weight decay\n",
    "        save_strategy='no', # No checkpoints saved during this final training\n",
    "        fp16=torch.cuda.is_available(), # Mixed precision\n",
    "        report_to='none', # No reporting\n",
    "    ),\n",
    "    train_dataset=full_train_tokenized, # The tokenized full training dataset\n",
    "    tokenizer=tokenizer, # The tokenizer\n",
    ")\n",
    "\n",
    "final_trainer.train() # Starts the final training process\n",
    "\n",
    "# ===== 13. Predict Test Set =====\n",
    "print(\"\\nPredicting test set...\")\n",
    "# Makes predictions on the tokenized test dataset using the finally trained model.\n",
    "predictions = final_trainer.predict(test_tokenized)\n",
    "# Extracts the predicted class labels (0 or 1) from the raw prediction scores (logits).\n",
    "pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# ===== 14. Generate Submission File =====\n",
    "# Creates a Pandas DataFrame for the submission file.\n",
    "# It includes the 'id' from the original test data and the predicted 'sentiment' labels.\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'sentiment': pred_labels\n",
    "})\n",
    "\n",
    "# Saves the submission DataFrame to a CSV file.\n",
    "# `index=False` prevents Pandas from writing the DataFrame index as a column in the CSV,\n",
    "# which is usually not required for Kaggle submissions.\n",
    "submission.to_csv('deberta_submission.csv', index=False)\n",
    "print(\"\\n✅ Submission file saved: deberta_submission.csv\")\n",
    "# Prints the distribution of the predicted sentiment labels in the submission file.\n",
    "print(f\"Prediction distribution: {pd.Series(pred_labels).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8487372,
     "sourceId": 13377615,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
