{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13377615,"sourceType":"datasetVersion","datasetId":8487372}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets accelerate -U -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T05:18:05.592515Z","iopub.execute_input":"2025-10-14T05:18:05.592673Z","iopub.status.idle":"2025-10-14T05:19:37.346148Z","shell.execute_reply.started":"2025-10-14T05:18:05.592658Z","shell.execute_reply":"2025-10-14T05:19:37.345420Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"\nDeBERTa-v3 Movie Review Sentiment Classification - Full Code for Kaggle Competition\nSuitable for: https://www.kaggle.com/competitions/py-sphere-movie-review-sentiment-challenge\nCurrent baseline: 0.81368 â†’ Target: 0.90+\n\"\"\"\n\n# ===== 1. Install Dependencies =====\n# Run in the first cell of Kaggle Notebook:\n# !pip install transformers datasets accelerate -U -q\n\n# ===== 2. Import Libraries =====\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import (\n    AutoTokenizer, # Used to load the tokenizer for the pre-trained model\n    AutoModelForSequenceClassification, # Used to load the pre-trained model for sequence classification\n    TrainingArguments, # Defines the training configuration for the Trainer\n    Trainer # A class for training PyTorch models with ğŸ¤— Transformers\n)\nfrom datasets import Dataset # Hugging Face's Dataset object for efficient data handling\nfrom sklearn.model_selection import train_test_split # Utility for splitting datasets into train and test sets\nfrom sklearn.metrics import accuracy_score, f1_score # Metrics to evaluate model performance\nimport warnings # Used to manage warnings\nwarnings.filterwarnings('ignore') # Ignores all warning messages for cleaner output\n\n# ===== 3. Set Random Seed (for reproducibility) =====\ndef set_seed(seed=42):\n    \"\"\"\n    Sets the random seed for NumPy, PyTorch, and CUDA to ensure reproducibility\n    of experiments.\n    \"\"\"\n    np.random.seed(seed) # Seed for NumPy random number generator\n    torch.manual_seed(seed) # Seed for PyTorch on CPU\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed) # Seed for PyTorch on all CUDA GPUs\n\nset_seed(42) # Call the function to set the global random seed\n\n# ===== 4. Load Data =====\n# Modify to your Kaggle data path if different\n# Loads the training, testing, and sample submission data from CSV files.\ntrain_df = pd.read_csv('/kaggle/input/py-sphere-movie-review-sentiment-challenge/train.csv')\ntest_df = pd.read_csv('/kaggle/input/py-sphere-movie-review-sentiment-challenge/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/py-sphere-movie-review-sentiment-challenge/sample_submission.csv')\n\n# Prints the size of the datasets and the distribution of sentiment labels in the training set.\nprint(f\"Training set size: {len(train_df)}\")\nprint(f\"Test set size: {len(test_df)}\")\nprint(f\"Positive/Negative sample distribution:\\n{train_df['sentiment'].value_counts()}\")\n\n# ===== 5. Data Preprocessing =====\n# Clean text data\ndef clean_text(text):\n    \"\"\"\n    Simple text cleaning function: converts text to string and removes leading/trailing whitespace.\n    Further cleaning (e.g., removing punctuation, special characters) might be added here.\n    \"\"\"\n    text = str(text).strip() # Ensure text is a string and remove whitespace\n    return text\n\n# Apply the cleaning function to the 'review' columns of both training and testing DataFrames.\ntrain_df['review'] = train_df['review'].apply(clean_text)\ntest_df['review'] = test_df['review'].apply(clean_text)\n\n# Split training set into training and validation sets (Crucial for realistic performance evaluation)\n# Splits `train_df` into `train_data` (90%) and `val_data` (10%).\n# `test_size=0.1`: 10% of the original training data will be used for validation.\n# `random_state=42`: Ensures the split is reproducible.\n# `stratify=train_df['sentiment']`: Maintains the same proportion of sentiment classes\n#                                   in both the training and validation splits as in the original `train_df`.\ntrain_data, val_data = train_test_split(\n    train_df,\n    test_size=0.1,\n    random_state=42,\n    stratify=train_df['sentiment'] # Keep category distribution consistent\n)\n\n# Prints the sizes and sentiment distributions of the newly created training and validation sets.\nprint(f\"\\nTraining data: {len(train_data)}, Validation data: {len(val_data)}\")\nprint(f\"Training data distribution: {train_data['sentiment'].value_counts().to_dict()}\")\nprint(f\"Validation data distribution: {val_data['sentiment'].value_counts().to_dict()}\")\n\n# ===== 6. Load Model and Tokenizer =====\nMODEL_NAME = \"microsoft/deberta-v3-base\" # Specifies the name of the pre-trained DeBERTa-v3 base model\n# If GPU memory is insufficient, you can use the small version:\n# MODEL_NAME = \"microsoft/deberta-v3-small\"\n\nprint(f\"\\nLoading model: {MODEL_NAME}\")\n# Loads the tokenizer associated with the specified pre-trained model.\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n# Loads the pre-trained DeBERTa-v3 model for sequence classification.\n# `num_labels=2`: Configures the model for binary classification (positive/negative sentiment).\n# `ignore_mismatched_sizes=True`: Allows loading weights even if some layers' sizes don't perfectly match,\n#                                  useful if the pre-trained model had a different number of output labels.\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,\n    ignore_mismatched_sizes=True\n)\n\n# ===== 7. Data Encoding =====\ndef tokenize_function(examples):\n    \"\"\"\n    Tokenizes a batch of text examples using the pre-trained tokenizer.\n    `padding='max_length'`: Pads shorter sequences to `max_length`.\n    `truncation=True`: Truncates longer sequences to `max_length`.\n    `max_length=256`: Sets the maximum sequence length for tokenization.\n                      Can be adjusted; longer sequences might yield better results but are slower.\n    \"\"\"\n    return tokenizer(\n        examples['review'],\n        padding='max_length',\n        truncation=True,\n        max_length=256 # Adjustable, longer might be slower but better results\n    )\n\n# Convert Pandas DataFrames to Hugging Face Dataset format\n# `from_pandas` creates a Dataset object from a DataFrame, selecting specified columns.\ntrain_dataset = Dataset.from_pandas(train_data[['review', 'sentiment']])\nval_dataset = Dataset.from_pandas(val_data[['review', 'sentiment']])\ntest_dataset = Dataset.from_pandas(test_df[['review']])\n\n# Rename column (Trainer requires 'label' column)\n# The `Trainer` expects the target column to be named 'labels', so we rename 'sentiment'.\ntrain_dataset = train_dataset.rename_column('sentiment', 'labels')\nval_dataset = val_dataset.rename_column('sentiment', 'labels')\n\n# Batch encoding\nprint(\"\\nEncoding data...\")\n# Apply the `tokenize_function` to each dataset in batches.\n# `batched=True`: Processes multiple examples at once for efficiency.\n# `remove_columns=['review']`: Removes the original 'review' text column after tokenization\n#                               to save memory, as the tokenized IDs are now the features.\ntrain_tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=['review'])\nval_tokenized = val_dataset.map(tokenize_function, batched=True, remove_columns=['review'])\ntest_tokenized = test_dataset.map(tokenize_function, batched=True, remove_columns=['review'])\n\n# ===== 8. Define Evaluation Metrics =====\ndef compute_metrics(eval_pred):\n    \"\"\"\n    Computes accuracy and F1-score for evaluation.\n    `eval_pred` is a tuple containing predictions (logits) and true labels.\n    \"\"\"\n    logits, labels = eval_pred # Unpack predictions (raw model outputs) and true labels\n    predictions = np.argmax(logits, axis=-1) # Convert logits to class predictions (0 or 1)\n    acc = accuracy_score(labels, predictions) # Calculate accuracy\n    f1 = f1_score(labels, predictions, average='binary') # Calculate F1-score for binary classification\n    return {\n        'accuracy': acc,\n        'f1': f1\n    }\n\n# ===== 9. Training Arguments Setup =====\ntraining_args = TrainingArguments(\n    output_dir='./results', # Directory where model checkpoints and outputs will be saved\n\n    # â­ Fixed parameter names for consistency with Hugging Face Transformers updates\n    eval_strategy='epoch', # Evaluate every epoch\n    save_strategy='epoch', # Save model checkpoints every epoch\n\n    # Learning rate and batch size\n    learning_rate=2e-5, # Initial learning rate for the optimizer\n    per_device_train_batch_size=16, # Batch size per GPU/CPU for training (reduce if Out Of Memory)\n    per_device_eval_batch_size=32, # Batch size per GPU/CPU for evaluation\n\n    # Number of training epochs\n    num_train_epochs=3, # Total number of training epochs (can try 4-5 for potentially better results)\n\n    # Regularization\n    weight_decay=0.01, # L2 regularization applied to all layers except bias and layer normalization weights\n\n    # Early stopping and model saving\n    load_best_model_at_end=True, # Loads the best model (based on `metric_for_best_model`) at the end of training\n    metric_for_best_model='accuracy', # Metric used to determine the \"best\" model to load\n\n    # Logging\n    logging_dir='./logs', # Directory for storing logs\n    logging_steps=50, # Log training progress every 50 steps\n\n    # Other settings\n    report_to='none', # Disables reporting to experiment tracking platforms like Weights & Biases\n    seed=42, # Random seed for reproducibility during training\n    fp16=torch.cuda.is_available(), # Automatically enables mixed precision training if a CUDA GPU is available\n)\n\n# ===== 10. Create Trainer and Train =====\n# Initializes the Hugging Face Trainer with the model, arguments, datasets, tokenizer, and metrics.\ntrainer = Trainer(\n    model=model, # The ğŸ¤— Transformers model to train\n    args=training_args, # The training arguments\n    train_dataset=train_tokenized, # The tokenized training dataset\n    eval_dataset=val_tokenized, # The tokenized validation dataset\n    tokenizer=tokenizer, # The tokenizer used for encoding (optional, but good practice to pass)\n    compute_metrics=compute_metrics, # The function to compute metrics during evaluation\n)\n\nprint(\"\\nStarting training...\")\ntrainer.train() # Starts the training process\n\n# ===== 11. Validation Set Evaluation =====\nprint(\"\\nEvaluating on validation set...\")\n# Evaluates the trained model on the validation set.\neval_results = trainer.evaluate()\n# Prints the accuracy and F1-score on the validation set.\nprint(f\"Validation Accuracy: {eval_results['eval_accuracy']:.4f}\")\nprint(f\"Validation F1 Score: {eval_results['eval_f1']:.4f}\")\n\n# ===== 12. Retrain on Full Training Data (Optional, usually improves by 1-2%) =====\nprint(\"\\nRetraining with full training data...\")\n# Creates a full training dataset from the original `train_df`.\nfull_train_dataset = Dataset.from_pandas(train_df[['review', 'sentiment']])\nfull_train_dataset = full_train_dataset.rename_column('sentiment', 'labels') # Rename 'sentiment' to 'labels'\nfull_train_tokenized = full_train_dataset.map(tokenize_function, batched=True, remove_columns=['review']) # Tokenize\n\n# Re-create Trainer (without validation set for final training)\n# A new Trainer is created for training on the *entire* original training dataset.\n# Validation is usually skipped in this final stage as the goal is to maximize performance on test data.\nfinal_trainer = Trainer(\n    model=model, # The same model (potentially fine-tuned from previous training)\n    args=TrainingArguments(\n        output_dir='./final_results', # Output directory for this final training run\n        per_device_train_batch_size=16, # Training batch size\n        num_train_epochs=3, # Number of epochs for this final training\n        learning_rate=2e-5, # Learning rate\n        weight_decay=0.01, # Weight decay\n        save_strategy='no', # No checkpoints saved during this final training\n        fp16=torch.cuda.is_available(), # Mixed precision\n        report_to='none', # No reporting\n    ),\n    train_dataset=full_train_tokenized, # The tokenized full training dataset\n    tokenizer=tokenizer, # The tokenizer\n)\n\nfinal_trainer.train() # Starts the final training process\n\n# ===== 13. Predict Test Set =====\nprint(\"\\nPredicting test set...\")\n# Makes predictions on the tokenized test dataset using the finally trained model.\npredictions = final_trainer.predict(test_tokenized)\n# Extracts the predicted class labels (0 or 1) from the raw prediction scores (logits).\npred_labels = np.argmax(predictions.predictions, axis=-1)\n\n# ===== 14. Generate Submission File =====\n# Creates a Pandas DataFrame for the submission file.\n# It includes the 'id' from the original test data and the predicted 'sentiment' labels.\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'sentiment': pred_labels\n})\n\n# Saves the submission DataFrame to a CSV file.\n# `index=False` prevents Pandas from writing the DataFrame index as a column in the CSV,\n# which is usually not required for Kaggle submissions.\nsubmission.to_csv('deberta_submission.csv', index=False)\nprint(\"\\nâœ… Submission file saved: deberta_submission.csv\")\n# Prints the distribution of the predicted sentiment labels in the submission file.\nprint(f\"Prediction distribution: {pd.Series(pred_labels).value_counts().to_dict()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T05:20:49.521603Z","iopub.execute_input":"2025-10-14T05:20:49.521921Z","iopub.status.idle":"2025-10-14T05:27:38.466259Z","shell.execute_reply.started":"2025-10-14T05:20:49.521897Z","shell.execute_reply":"2025-10-14T05:27:38.465609Z"}},"outputs":[{"name":"stderr","text":"2025-10-14 05:21:00.793670: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760419260.986714      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760419261.042540      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Training set size: 1600\nTest set size: 5001\nPositive/Negative sample distribution:\nsentiment\n1    801\n0    799\nName: count, dtype: int64\n\nTraining data: 1440, Validation data: 160\nTraining data distribution: {1: 721, 0: 719}\nValidation data distribution: {0: 80, 1: 80}\n\nLoading model: microsoft/deberta-v3-base\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b5243708ac74c538beaa9631e1530ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"690c89fd3d22457cb972ec05f6264586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a821f4cc6404c57b65862388adad285"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3afd3e784bf4496a5ba9ce15466afd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821d6cc19a48423ba3e079e5a020fa3a"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEncoding data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1440 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"139e912ab10642f6baec563c9d5be8d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40c03c8e866b4f589c1567199c6d5e0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6094e372ceb42d9ba7da1b7a684c2dd"}},"metadata":{}},{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n","output_type":"stream"},{"name":"stdout","text":"\nStarting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [270/270 02:38, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.314100</td>\n      <td>0.000613</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.001000</td>\n      <td>0.000285</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000600</td>\n      <td>0.000232</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nEvaluating on validation set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Validation Accuracy: 1.0000\nValidation F1 Score: 1.0000\n\nRetraining with full training data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27edc8c58a354153a66f18d39c24881e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 02:36, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nPredicting test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nâœ… Submission file saved: deberta_submission.csv\nPrediction distribution: {0: 2522, 1: 2479}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}